---
title: "Bayesian Statistics in Social Sciences"
format: revealjs
editor: visual
---

## Hierarchical priors

$$
y \sim \beta_0 + \beta_1x\\
\beta_0, \beta_1 \sim \mathcal{Normal}(m, s)\\
m \sim \mathcal{Normal}(0, 1)\\
s \sim \mathcal{HalfNormal}(0, 1)
$$

$\beta_0, \beta_1$ have their prior distributions

$m, s$ have their hyperprior distributions

## Hierarchical priors

```{r message=FALSE}
library(tidyverse)
library(cowplot)
theme_set(theme_classic())
set.seed(1010)
lev1_mu <- 15
lev1_sd <- 5
lev2_mu <- rnorm(5, lev1_mu, lev1_sd)
lev2_sd <- 2
p1 <- tibble(parameter = seq(0, 30, length.out = 50)) %>% 
  ggplot(aes(parameter))+
  stat_function(fun=dnorm, args = list(mean=lev1_mu, sd=lev1_sd), 
                geom = "area", alpha = 1/2, fill="skyblue")+
  geom_vline(xintercept = lev2_mu, linetype=2, colour="red")+
  labs(x="",y="",title = "Hyperpriors")
p2 <- tibble(parameter = seq(0, 30, length.out = 50)) %>% 
  ggplot(aes(parameter))+
  stat_function(fun=dnorm, args = list(mean=lev2_mu[1], sd=lev2_sd), 
                geom = "area", alpha = 1/3, fill="red")+
  stat_function(fun=dnorm, args = list(mean=lev2_mu[2], sd=lev2_sd), 
                geom = "area", alpha = 1/3, fill="red")+
  stat_function(fun=dnorm, args = list(mean=lev2_mu[3], sd=lev2_sd), 
                geom = "area", alpha = 1/3, fill="red")+
  stat_function(fun=dnorm, args = list(mean=lev2_mu[4], sd=lev2_sd), 
                geom = "area", alpha = 1/3, fill="red")+
  stat_function(fun=dnorm, args = list(mean=lev2_mu[5], sd=lev2_sd), 
                geom = "area", alpha = 1/3, fill="red")+
  geom_vline(xintercept = lev2_mu, linetype=2, colour="red")+
  labs(x="Parameter",y="",title = "Priors")
plot_grid(p1,p2,ncol = 1)
```

## Hierarchical Bayesian models

-   Hierarchical linear models
-   Multilevel linear models
-   Mixed effects linear models
-   Random effects models

## <small>Dealing with structure in linear models</small>

-   *students* nested in
-   *classes* nested in
-   *schools* nested in
-   *districts*

## <small>Dealing with structure in linear models</small>

-   *employees* nested in
-   *sections* nested in
-   *departments* nested in
-   *branches*

## <small>Dealing with structure in linear models</small>

-   *voters* nested in
-   *communes* nested in
-   *counties* nested in
-   *voivodeships*

## <small>Dealing with structure in linear models</small>

-   *trials* nested in
-   *blocks* nested in
-   *measurements* nested in
-   *conditions*

## Stucture of errors in linear models

$$
\mathbf{\epsilon} = \begin{bmatrix}
\epsilon_{11} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & \epsilon_{22} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & \epsilon_{33} & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & \epsilon_{44} & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & \epsilon_{55} & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & \epsilon_{66} & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & \epsilon_{77} & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \epsilon_{88} & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \epsilon_{99} 
\end{bmatrix}
$$

## Stucture of errors in linear models

$$
\mathbf{\epsilon} = \begin{bmatrix}
\epsilon_{11} & \epsilon_{12} & \epsilon_{13} & 0 & 0 & 0 & 0 & 0 & 0 \\
\epsilon_{21} & \epsilon_{22} & \epsilon_{23} & 0 & 0 & 0 & 0 & 0 & 0 \\
\epsilon_{31} & \epsilon_{32} & \epsilon_{33} & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & \epsilon_{44} & \epsilon_{45} & \epsilon_{46} & 0 & 0 & 0 \\
0 & 0 & 0 & \epsilon_{54} & \epsilon_{55} & \epsilon_{56} & 0 & 0 & 0 \\
0 & 0 & 0 & \epsilon_{64} & \epsilon_{65} & \epsilon_{66} & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & \epsilon_{77} & \epsilon_{78} & \epsilon_{79} \\
0 & 0 & 0 & 0 & 0 & 0 & \epsilon_{87} & \epsilon_{88} & \epsilon_{89} \\
0 & 0 & 0 & 0 & 0 & 0 & \epsilon_{97} & \epsilon_{98} & \epsilon_{99} 
\end{bmatrix}
$$

## Why use hierarchical models?

-   Can deal with interdependence between clustered observations -\> reduce bias in regression coefficients
-   Can be used instead of aggregation of several responses -\> better describe variance components
-   Can be used to introduce predictors at various levels -\> modeling contextual effects

## <small>Why use Bayesian hierarchical models?</small>

-   Bayesian (vs. frequentists) hierarchical models are more intuitive: see hierarchical priors
-   Bayesian (vs. frequentists) hierarchical models can be used even when number of clusters at higher levels is quite small
-   Bayesian (vs. frequentists) hierarchical models can more easily recover group/cluster effects

## Null model

$$
y_{ij} \sim \mathcal{N}(\mu_{j},\ \sigma)\\
\mu_{j} \sim \mathcal{N}(\gamma_{00},\ \tau_{0})\\
\gamma_{00} \sim \mathcal{N}(0, 1)\\
\tau_0 \sim \mathcal{HN}(0, 1)\\
\sigma \sim \mathcal{HN}(0, 1)
$$

## Random intercept model

$$
y_{ij} \sim \mathcal{N}(\mu_{ij},\ \sigma)\\
\mu_{ij} = \beta_{j0} + \beta_{1}x_{ij}\\
\beta_{j0} \sim \mathcal{N}(\gamma_{00},\ \tau_{0})\\
\beta_{1} \sim \mathcal{N}(0, 1)\\
\gamma_{00} \sim \mathcal{N}(0, 1)\\
\tau_0 \sim \mathcal{HN}(0, 1)\\
\sigma \sim \mathcal{HN}(0, 1)
$$

## Random slope model

$$
y_{ij} \sim \mathcal{N}(\mu_{ij},\ \sigma)\\
\mu_{ij} = \beta_{0} + \beta_{j1}x_{ij}\\
\beta_{0} \sim \mathcal{N}(0, 1)\\
\beta_{j1} \sim \mathcal{N}(\gamma_{10},\ \tau_{1})\\
\gamma_{10} \sim \mathcal{N}(0, 1)\\
\tau_1 \sim \mathcal{HN}(0, 1)\\
\sigma \sim \mathcal{HN}(0, 1)
$$

## Random intercept-and-slope model

$$
y_{ij} \sim \mathcal{N}(\mu_{ij},\ \sigma)\\
\mu_{ij} = \beta_{j0} + \beta_{j1}x_{ij}\\
\beta_{j0} \sim \mathcal{N}(\gamma_{00},\ \tau_{0})\\
\beta_{j1} \sim \mathcal{N}(\gamma_{10},\ \tau_{1})\\
\gamma_{00}, \gamma_{10}  \sim \mathcal{N}(0, 1)\\
\tau_0, \tau_1 \sim \mathcal{HN}(0, 1)\\
\sigma \sim \mathcal{HN}(0, 1)
$$

## Contextual effects

$$
y_{ij} \sim \mathcal{N}(\mu_{ij},\ \sigma)\\
\mu_{ij} = \beta_{j0} + \beta_{j1}x_{ij}\\
\beta_{j0} \sim \mathcal{N}(\gamma_{00} + \gamma_{01}Z_j,\ \tau_{0})\\
\beta_{j1} \sim \mathcal{N}(\gamma_{10},\ \tau_{1})\\
\gamma_{00}, \gamma_{01}, \gamma_{10} \sim \mathcal{N}(0, 1)\\
\tau_0, \tau_1 \sim \mathcal{HN}(0, 1)\\
\sigma \sim \mathcal{HN}(0, 1)
$$

## Cross-level interactions

$$
y_{ij} \sim \mathcal{N}(\mu_{ij},\ \sigma)\\
\mu_{ij} = \beta_{j0} + \beta_{j1}x_{ij}\\
\beta_{j0} \sim \mathcal{N}(\gamma_{00} + \gamma_{01}Z_j,\ \tau_{0})\\
\beta_{j1} \sim \mathcal{N}(\gamma_{10} + \gamma_{11}Z_j,\ \tau_{1})\\
\gamma_{00}, \gamma_{01}, \gamma_{10}, \gamma_{11} \sim \mathcal{N}(0, 1)\\
\tau_0, \tau_1 \sim \mathcal{HN}(0, 1)\\
\sigma \sim \mathcal{HN}(0, 1)
$$

## Final test

-   Bayesian workflow
-   SEXIT framework testing
-   Model selection with information criteria
-   Linear regression models (with robust models)
-   Models with interactions (probing interactions)
-   Generalized linear models (with dichotomous, ordinal, and nominal predicted variables)

## Final test

-   40 minutes to
-   conduct a full Bayesian analysis (on a selected problem), describe and interpret the results
-   you can use your notes, your home assignments, class slides and notebooks, as well as `brms` and R documentation
-   consulting with others is prohibited
