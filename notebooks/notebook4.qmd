---
title: "Class 4 notebook"
format: html
editor: visual
---

## Load libraries and data

Load the required libraries. We will use `ggplot2` for plotting functions. You don't have to install it, it was be installed with `brms`.
I don't like the default theme in `ggplot2`, so I will set the theme to `theme_classic`

```{r}
library(brms)
library(bayestestR)
library(ggplot2)
theme_set(theme_classic())
```


We will load a dataset. This data are the results of an experiment which tested how arousing control motivation affect vaccination intentions.
- cond - experimental condition: 
  - Base = baseline condition (participants read a vignette about benefits)
  - Rest = control restoration condition (participants read a vignette about how vaccines can allow people for control restoration)
- vaccination - intentions to vaccinate against several diseases
- gender - participant's gender
- age - participant's age
- place - place of living (rural vs. urban)

```{r}
vacc <- read.csv2("data_files/exp_vaccines.csv")
vacc
```


## Comparing two groups

First, it is always good to look at the distribution of outcome variable across conditions.
Violin plots will give us density for both conditions.
Boxplots will show us different quantiles of the distributions.
Notches of the boxplots, are similar to 95% CIs. Non-overlap suggests that the two medians differ.

```{r}
ggplot(data = vacc,
       mapping = aes(x = cond, y = vaccination,
                     fill = cond)) +
  geom_violin()+
  geom_boxplot(notch = TRUE, width=0.4)
```


### Simple approach

In most cases, we want our data standardized (z-score). The inbuilt function may work fine, but I prefer to use my own.

```{r}
my_scale <- function(x){
  (x - mean(x, na.rm=T))/sd(x, na.rm=)
}
```


Standardize the outcome variable (vaccination intentions).

```{r}
vacc$z_vacc <- my_scale(vacc$vaccination)
```


Let's fit the model where vaccination intentions are regressed on a dummy variable denoting experimental condition (0 = baseline, 1 = control restoration).

Always think about defining prior.

```{r}
get_prior(
  formula = z_vacc ~ cond,
  data = vacc
)
```

The prior for the dummy variable is flat. Let's use a weakly informative prior instead.

```{r}
priors1 <- c(
  set_prior("normal(0, 1)", class="b")
)
```

Let's fit the model with `brm`. In most cases, I recommend setting `sample_prior` to TRUE. 
This will give us additional options later.

```{r}
fit1 <- brm(
  formula = z_vacc ~ 1 + cond,
  data = vacc,
  prior = priors1,
  sample_prior = "yes"
)
```

Let's see the results.
**Remember that in before looking at the results you should also check convergence of MCMC and conduct posterior predictive checks.**

```{r}
fit1
```

Let's test the hypothesis that the difference between conditions is 0.

```{r}
hypothesis(fit1, "condRest = 0")
```


### Kruschke's approach (BEST = Bayesian estimation supersedes t-test)

If we get rid of the intercept (in formula 0 instead of 1), we can explicitly estimate means in both conditions.
We model not only means ($\mu$) but also residual standard deviation ($\sigma$) as dependent on experimental condition.
We will use `bf` function to link together several formulas.

```{r}
fit2_formula <- bf(vaccination ~ 0 + cond,
                   sigma ~ 0 + cond)
```

Let's try to understand how this model looks like in `brms`:
```{r}
get_prior(
  formula = fit2_formula,
  data = vacc,
  family = student
)
```

Kruschke suggests to set prior for group means ($\mu$) to Normal distribution with mean equal to sample mean and standard deviation equal to sample SD x 100.
Moreover, he suggests to set prior for group standard deviations (dpar=distributional parameter, $\sigma$) to HalNormal distribution with mean equal to 0 and standard deviation equalt sample SD. Because in brms $\sigma$ is always used on a log-scale, we need to input logged sample SD.
Finally, he suggests to set prior for degrees of freedom ($\nu$) of the Student distribution of groups' results to Exponential with rate parameters set to 1/29.


The template for prior definition is:
```
c(prior(normal(mean_y, sd_y * 100), class = b),
  prior(normal(0, log(sd_y)), class = b, dpar = sigma),
  prior(exponential(one_over_twentynine), class = nu))
```

There are more elegant ways coding this prior, but for the sake of simplity, we will simply compute each hyperparameter value and put it into our code.

Sample mean
```{r}
mean(vacc$vaccination)
```

Sample SD * 100
```{r}
sd(vacc$vaccination) * 100
```

Logged sample SD.
```{r}
log(sd(vacc$vaccination))
```

Rate of the Exponential prior
```{r}
1/29
```

Let's put the values into the template.

```{r}
fit2_priors <- c(prior(normal(4.924107, 148.6153), class = b),
                prior(normal(0, 0.3961912), class = b, dpar = sigma),
                prior(exponential(0.03448276), class = nu))
```

Let's fit the model with `brm`.

```{r}
fit2 <- brm(
  formula = fit2_formula,
  data = vacc,
  family = student,
  prior = fit2_priors
)
```

Let's see the results.
**Remember that in before looking at the results you should also check convergence of MCMC and conduct posterior predictive checks.**
```{r}
fit2
```

One way to get the estimate of the difference between conditions is to use `hypothesis`.

```{r}
difference <- hypothesis(fit2, "condRest - condBase = 0")
difference
```

To get the value of the effect size (Cohen's d), we need to divide the difference by the pooled standard deviation.

$$
\sigma_{p} = \sqrt{\frac{\sigma^2_1 + \sigma^2_2}{2}}
$$
Because $\sigma$ is on a log-scale, we need to transform it back to linear scale, with an `exp` function.
```{r}
effect_size <- hypothesis(fit2, "(condRest - condBase)/sqrt((exp(sigma_condRest)^2 + exp(sigma_condBase)^2)/2) = 0")
effect_size
```

You can get the posterior sample for both the difference and the effect size, but using the socket called `samples`. You can use this object with `p_direction`...
```{r}
p_direction(effect_size$samples)
```

... or `equivalence_test`
```{r}
equivalence_test(effect_size$samples)
```


## Simple linear regression

### Simple approach

Always plot results before running any linear regression. 
If you have more than several hundred of observations, you may want to use `geom_jitter` instead of `geom_point`.
Use `geom_smooth` to check whether it can be safely assumed that the relationship between an outcome variable and it's predictor is linear.
```{r}
ggplot(data = vacc,
       mapping = aes(x = age, y = vaccination)) +
  geom_point()+
# geom_jitter()+
  geom_smooth()
```

Standardize the predictor.
```{r}
vacc$zAge <- my_scale(vacc$age)
```

Let's try to understand how the model is implemented in `brms`.
```{r}
get_prior(
  formula = z_vacc ~ zAge,
  data = vacc
)
```

Because both variables are standardized, the slope will also be standardized. It will thus be equal to Pearson r value. We can safely use a prior like Normal(0, 1).

```{r}
priors3 <- c(
  set_prior("normal(0, 1)", class="b")
)
```

Let's fit the model with `brm`.
```{r}
fit3 <- brm(
  formula = z_vacc ~ zAge,
  data = vacc,
  prior = priors3,
  sample_prior = "yes"
)
```

Let's see the results.
**Remember that in before looking at the results you should also check convergence of MCMC and conduct posterior predictive checks.**
```{r}
fit3
```

Let's check whether slope/correlation is different from 0.
```{r}
slope <- hypothesis(fit3, "zAge = 0")
slope
```

What is the probability of the corelation being positive?
```{r}
p_direction(slope$samples)
```

Is this correlation of practical significance?
```{r}
equivalence_test(slope$samples)
```

Let's plot the model's effects using `conditional_effects`.
```{r}
conditional_effects(x = fit3, 
                    effects = "zAge")
```

Another way to diplay the results is to draw regression lines from the posterior and present them as a spaghetti plot.

```{r}
conditional_effects(x = fit3,
                    effects = "zAge", 
                    spaghetti = TRUE, 
                    ndraws=200)
```

To better see the mean posterior, we need to tweak this code a little bit.

```{r}
plot(
  conditional_effects(x = fit3,
                    effects = "zAge", 
                    spaghetti = TRUE, 
                    ndraws=200),
  line_args = list(colour="red")
)
```


### Robust regression

If we want to conduct a regression analysis robust to outliers, we may use Student likelihood instead of the Normal likelihood. Let's understand how this model is implemented in `brms`.

```{r}
get_prior(
  formula = z_vacc ~ zAge,
  data = vacc,
  family = student
)
```

Following Kruschke's recommendations, we will set:
- prior for the intercept to Normal(0, 10)
- prior for the slope to Normal(0, 10)
- prior for residual standard deviation to HalfNormal(0, 1)
- prior for degrees of freedom of the Student likelihood to Exponential(1/29)

```{r}
priors4 <- c(prior(normal(0, 10), class = Intercept),
            prior(normal(0, 10), class = b),
            prior(normal(0, 1), class = sigma),
            prior(exponential(0.03448276), class = nu))
```

Let's fit the model with `brm`.

```{r}
fit4 <- brm(
  formula = z_vacc ~ zAge,
  data = vacc,
  family = student,
  prior = priors4,
  sample_prior = "yes"
)
```

Let's see the results.
**Remember that in before looking at the results you should also check convergence of MCMC and conduct posterior predictive checks.**
```{r}
fit4
```

Plot the results for the robust model.
```{r}
plot(
  conditional_effects(x = fit4,
                    effects = "zAge", 
                    spaghetti = TRUE, 
                    ndraws=200),
  line_args = list(colour="red")
)
```

## Polynomial regression

So far, we assumed that the relationship between the vaccination intentions and age can be modeled as a straight line. But perhaps you would like to test a curvilinear relationship?

Let's see how this model would look like in `brms`.
We will use the `poly` function to create polynomial terms of a second degree.
The first term 'polyzAge21' is a slope of the regression line at the value of x (i.e., zAge) equal to 0.
The second term 'polyzAge22' is the quadratic term. Positive values indicate U-shape. Negative values indicate inverted U-shape.

```{r}
get_prior(
  formula = z_vacc ~ poly(zAge, 2),
  data = vacc,
  family = student
)
```

Let's use similar priors as with `fit4`.
```{r}
priors5 <- c(prior(normal(0, 10), class = Intercept),
            prior(normal(0, 10), class = b),
            prior(normal(0, 1), class = sigma),
            prior(exponential(0.03448276), class = nu))
```

Let's fit the model with `brm`.
```{r}
fit5 <- brm(
  formula = z_vacc ~ poly(zAge, 2),
  data = vacc,
  family = student,
  prior = priors5,
  sample_prior = "yes"
)
```

Let's see the results.
**Remember that in before looking at the results you should also check convergence of MCMC and conduct posterior predictive checks.**
```{r}
fit5
```

Let's plot the results.

```{r}
plot(
  conditional_effects(x = fit5,
                    effects = "zAge", 
                    spaghetti = TRUE, 
                    ndraws=200),
  line_args = list(colour="red")
)
```

## Comparing models using $R^2$

But the model results and it's graphical presentation speak against the hypothesis of the quadratic relationship.
However, which of the model explains the outcome variable better.

Let's use bayesian version of R-squared.

For a linear model:
```{r}
bayes_R2(fit4)
```

For a quadratic model:
```{r}
bayes_R2(fit5)
```

## Comparing models using information criteria

We can use information criteria to account for the model complexity and overfitting.


Let's compute LOO (leave-one-out) information criterion for the linear model.

```{r}
loo4 <- loo(fit4)
loo4
```
Let's compute LOO (leave-one-out) information criterion for quadratic model.

```{r}
loo5 <- loo(fit5)
loo5
```
The model with higher elpd_loo (or lower looic) should be preferred, as one with better out-of-sample predictive qualities.

We can compare both IC with `loo_compare`.
```{r}
loo_compare(loo4, loo5)
```

An elpd_diff at least twice larger than se_diff indicate certainty about model superiority.
